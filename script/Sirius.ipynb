{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual project in pairs completed by Scott Pan and Federico Loguercio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With autocratic leaders getting to power in several countries, fake news are becoming an increasingly frequent problem. In most cases, human checking of these news is both unfeasible and inaccurate. In the following notebook we develop a model capable of correctly classifying fake and real news over 94% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure will be as follows:\n",
    "\n",
    "First, we begin with some exploratory data analysis to get a feel for the data we are working with\n",
    "\n",
    "Then, a baseline will be fit. Subsequently, different models will be fit, exploring several different iterations. These include various steps of preprocessing (such as stemming and lemmatizing), the use of different vectorizers (count and tfidf), as well as feature engineering (occurence of elements such as a date or the word \"Trump\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import helpers as hp\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from nltk import word_tokenize, WordPunctTokenizer, pos_tag\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,ExtraTreesClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/fake_or_real_news_training.csv')\n",
    "# the submission data has no label\n",
    "submission = pd.read_csv('../data/fake_or_real_news_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set initial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will be used throughout some functions and can be modified easily.\n",
    "TARGET_VARIABLE = 'label'\n",
    "METRIC = 'accuracy'\n",
    "SEED = 123\n",
    "TIMESERIES = False\n",
    "SPLITS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                              title  \\\n",
       "0   8476                       You Can Smell Hillary’s Fear   \n",
       "1  10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2   3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3  10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4    875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label   X1   X2  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  NaN  NaN  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  NaN  NaN  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  NaN  NaN  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  NaN  NaN  \n",
       "4  It's primary day in New York and front-runners...  REAL  NaN  NaN  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that two extra columns were created, X1 and X2. This is due to the fact that the title is not in quotes such that, if there is a comma in the title, it get's separated at that point and all the other column get shifted. The following cell will take care of that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = hp.rearrange(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                              title  \\\n",
       "0   8476                       You Can Smell Hillary’s Fear   \n",
       "1  10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2   3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3  10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4    875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see some key distribution metrics of our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportion of fake-news:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4978744686171543"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.loc[train['label'] == 'FAKE'])/len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore text length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribution of Text length')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_len = pd.DataFrame([len(t) for t in train.text])\n",
    "sns.set()\n",
    "sns.distplot(text_len, hist = False, color = \"darkblue\").set_title(\"Distribution of Text length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution is highly skewed to the right, there are some very long texts but most lie between 0 and 10000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a baseline without further preprocessing using the countvectorizer. Only the text will be used for now, the title will not be considered yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initiate scores-dataframe that will track scores, using one of the helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores  = pd.DataFrame(columns = ['Model', 'CV Score avg', 'CV Score max', 'Holdout Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count-vectorize data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test internally, in order to be able to evaluate how the model will perform on an unseen dataset. Throughout modelling, transformations will be learned on the train set and applied on the test set (as done below with the vectorizer). Within the train set, we will use cross validation. A gap between CV-performance and test performance will indicate over/underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "def split_data(data, feature='text', random_state = 7):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data[feature], data['label'],\n",
    "                                                        test_size = 0.2, random_state = random_state)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_baseline, X_test_baseline, y_baseline, y_test_baseline = split_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiaulize countvectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform \n",
    "count_train = count_vectorizer.fit_transform(X_baseline) \n",
    "\n",
    "# Transform the test set \n",
    "count_test = count_vectorizer.transform(X_test_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Naive Bayes for a first classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0  FAKE  REAL\n",
      "label            \n",
      "FAKE    348    57\n",
      "REAL     27   368\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Score avg</th>\n",
       "      <th>CV Score max</th>\n",
       "      <th>Holdout Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.877145</td>\n",
       "      <td>0.900156</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  CV Score avg  CV Score max  Holdout Score\n",
       "0  baseline      0.877145      0.900156          0.895"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MltNB = MultinomialNB() \n",
    "\n",
    "cv_score_baseline, test_score_baseline = hp.cv_evaluate(count_train, y_baseline, count_test, y_test_baseline,\n",
    "                                                     MltNB)\n",
    "all_scores = hp.append_scores(all_scores, 'baseline', cv_score_baseline, test_score_baseline)\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems fairly easy to classify a good amount of the news correctly. Nevertheless, we can see that the model performs worse on the fake news than on the worse news, recall is somewhat lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some standard preprocessing will be applied in order to evaluate whether that improves model performance.\n",
    "At this stage, that includes: turning all words to lowercase and creating a \"word\" indicating whether a text contains dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                              title  \\\n",
       "0   8476                       You Can Smell Hillary’s Fear   \n",
       "1  10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2   3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3  10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4    875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>you can smell hillary ’ s fear</td>\n",
       "      <td>daniel greenfield , a shillman journalism fell...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>watch the exact moment paul ryan committed pol...</td>\n",
       "      <td>google pinterest digg linkedin reddit stumbleu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>kerry to go to paris in gesture of sympathy</td>\n",
       "      <td>u.s. secretary of state john f. kerry said mon...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>bernie supporters on twitter erupt in anger ag...</td>\n",
       "      <td>— kaydee king ( @ kaydeeking ) november 9 , 20...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>the battle of new york : why this primary matters</td>\n",
       "      <td>it 's primary day in new york and front-runner...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                              title  \\\n",
       "0   8476                     you can smell hillary ’ s fear   \n",
       "1  10294  watch the exact moment paul ryan committed pol...   \n",
       "2   3608        kerry to go to paris in gesture of sympathy   \n",
       "3  10142  bernie supporters on twitter erupt in anger ag...   \n",
       "4    875  the battle of new york : why this primary matters   \n",
       "\n",
       "                                                text  label  \n",
       "0  daniel greenfield , a shillman journalism fell...      0  \n",
       "1  google pinterest digg linkedin reddit stumbleu...      0  \n",
       "2  u.s. secretary of state john f. kerry said mon...      1  \n",
       "3  — kaydee king ( @ kaydeeking ) november 9 , 20...      0  \n",
       "4  it 's primary day in new york and front-runner...      1  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_1 = hp.prepare_data(train, lower = True, date = True)\n",
    "train_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize\n",
    "def vectorize_select(selection=\"tfidf\", max_df=0.8, min_df=1, lowercase = True):\n",
    "    \"\"\"\n",
    "    \"tfidf\":\"TfidVectorizer\"\n",
    "    \"count\":\"CountVectorizer\"\n",
    "    \"hash\":\"HashingVectorizer\"\n",
    "    \"\"\"\n",
    "    if selection == \"tfidf\":\n",
    "        return TfidfVectorizer(stop_words='english', max_df=max_df, min_df=min_df,binary=True,\n",
    "                              lowercase=lowercase)\n",
    "    elif selection == \"count\":\n",
    "        return CountVectorizer(stop_words='english', max_df=max_df, min_df=min_df)\n",
    "    elif selection == \"hash\":\n",
    "        return HashingVectorizer(stop_words='english')\n",
    "    else:\n",
    "        raise Exception(\"{} can't be found\".format(selection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the slightly preprocessed data, let's try different vectorizers (tfidf, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ti-idf vectorize MultinomialNB model\n",
    "def nb_model(data, selection='tfidf', vectorize_max_df=0.8):\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(data)\n",
    "    \n",
    "    # vectorizer: selection: 'tfidf','count','hash'\n",
    "    vectorizer = vectorize_select(selection, max_df=vectorize_max_df)\n",
    "    # transform data\n",
    "    vectorize_train = vectorizer.fit_transform(X_train)\n",
    "    vectorize_test = vectorizer.transform(X_test)\n",
    "\n",
    "    # model\n",
    "    model = MultinomialNB(alpha=0.1)\n",
    "    cv_scores = cross_val_score(model,\n",
    "                                vectorize_train,\n",
    "                                y_train,\n",
    "                                cv = 5)\n",
    "    model.fit(vectorize_train, y_train)\n",
    "    pred = model.predict(vectorize_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    \n",
    "    #print(\"accuracy:   %0.3f\" % acc)\n",
    "    print(pd.crosstab(y_test, pred))\n",
    "    \n",
    "    return MltNB, cv_scores, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Naive Bayes with count vectorizer...\n",
      "col_0    0    1\n",
      "label          \n",
      "0      352   53\n",
      "1       28  367\n",
      "Fitting Naive Bayes with tfidf vectorizer...\n",
      "col_0    0    1\n",
      "label          \n",
      "0      345   60\n",
      "1       15  380\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Score avg</th>\n",
       "      <th>CV Score max</th>\n",
       "      <th>Holdout Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.877145</td>\n",
       "      <td>0.900156</td>\n",
       "      <td>0.89500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB count</td>\n",
       "      <td>0.883401</td>\n",
       "      <td>0.903276</td>\n",
       "      <td>0.89875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB tfidf</td>\n",
       "      <td>0.884020</td>\n",
       "      <td>0.915757</td>\n",
       "      <td>0.90625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  CV Score avg  CV Score max  Holdout Score\n",
       "0  baseline      0.877145      0.900156        0.89500\n",
       "1  NB count      0.883401      0.903276        0.89875\n",
       "2  NB tfidf      0.884020      0.915757        0.90625"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for vect in ['count', 'tfidf']:\n",
    "    print(\"Fitting Naive Bayes with \" + vect + \" vectorizer...\")\n",
    "    \n",
    "    model_temp, cv_scores_temp, test_score_temp = nb_model(train_1, vect, 0.8)\n",
    "    all_scores = hp.append_scores(all_scores, 'NB ' + vect, cv_scores_temp, test_score_temp)\n",
    "    \n",
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning all to lowercase and creating the date-variable improved the model slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vary the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ti-idf vectorize rf model\n",
    "def rf_model(data,selection='tfidf',vectorize_max_df=0.8):\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(data)\n",
    "    \n",
    "    # vectorizer: selection: 'tfidf','count','hash'\n",
    "    vectorizer = vectorize_select(selection, max_df=vectorize_max_df)\n",
    "    # transform data\n",
    "    vectorize_train = vectorizer.fit_transform(X_train)\n",
    "    vectorize_test = vectorizer.transform(X_test)\n",
    "    \n",
    "    # pipeline\n",
    "    estimators = [('RF',RandomForestClassifier(random_state=666,n_estimators=100,max_depth=20))]\n",
    "    pipe = Pipeline(estimators)\n",
    "    # specify a small grid\n",
    "    param_RF = {'RF__max_depth': [20,25],\n",
    "                'RF__n_estimators': [100,150]}\n",
    "    \n",
    "    # apply the estimators and parameters in pipeline\n",
    "    gridPipe = GridSearchCV(pipe, param_RF, cv=5, return_train_score=True)\n",
    "    model = gridPipe.fit(vectorize_train, y_train)\n",
    "\n",
    "    pred = model.predict(vectorize_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    \n",
    "    cv_results = gridPipe.cv_results_['mean_test_score']\n",
    "    \n",
    "    #print(\"accuracy:   %0.3f\" % acc)\n",
    "    print(confusion_matrix(y_test, pred, labels=[0, 1]))\n",
    "    \n",
    "    return model, cv_results, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the random forest classifier with the different vectorizers. Here we also can use the hash vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Random Forest with count vectorizer...\n",
      "[[373  32]\n",
      " [ 47 348]]\n",
      "Fitting Random Forest with hash vectorizer...\n",
      "[[363  42]\n",
      " [ 67 328]]\n",
      "Fitting Random Forest with tfidf vectorizer...\n",
      "[[367  38]\n",
      " [ 41 354]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Score avg</th>\n",
       "      <th>CV Score max</th>\n",
       "      <th>Holdout Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.877145</td>\n",
       "      <td>0.900156</td>\n",
       "      <td>0.89500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB count</td>\n",
       "      <td>0.883401</td>\n",
       "      <td>0.903276</td>\n",
       "      <td>0.89875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB tfidf</td>\n",
       "      <td>0.884020</td>\n",
       "      <td>0.915757</td>\n",
       "      <td>0.90625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF count</td>\n",
       "      <td>0.860425</td>\n",
       "      <td>0.866833</td>\n",
       "      <td>0.90125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF hash</td>\n",
       "      <td>0.828384</td>\n",
       "      <td>0.830259</td>\n",
       "      <td>0.86375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF tfidf</td>\n",
       "      <td>0.854720</td>\n",
       "      <td>0.856518</td>\n",
       "      <td>0.90125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  CV Score avg  CV Score max  Holdout Score\n",
       "0  baseline      0.877145      0.900156        0.89500\n",
       "1  NB count      0.883401      0.903276        0.89875\n",
       "2  NB tfidf      0.884020      0.915757        0.90625\n",
       "3  RF count      0.860425      0.866833        0.90125\n",
       "4   RF hash      0.828384      0.830259        0.86375\n",
       "5  RF tfidf      0.854720      0.856518        0.90125"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for vect in ['count', 'hash', 'tfidf']:\n",
    "    print(\"Fitting Random Forest with \" + vect + \" vectorizer...\")\n",
    "    \n",
    "    model_temp, cv_scores_temp, test_score_temp = rf_model(train_1, vect, 0.8)\n",
    "    all_scores = hp.append_scores(all_scores, 'RF ' + vect, cv_scores_temp, test_score_temp)\n",
    "    \n",
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the performance of the Random Forest is better than that of Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea behind how the passive aggresive classifier works is: As long as it classifies correctly, keep the model (passive). When it misclassifies a sample, it readjusts the model (aggressive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PAC(data, selection='tfidf', vectorize_max_df=0.8, feature='text', lowercase = True):\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(data, feature=feature)\n",
    "    # vectorizer: selection: 'tfidf','count','hash'\n",
    "    vectorizer = vectorize_select(selection, max_df=vectorize_max_df, lowercase = lowercase)\n",
    "    # transform data\n",
    "    vectorize_train = vectorizer.fit_transform(X_train)\n",
    "    vectorize_test = vectorizer.transform(X_test)\n",
    "    # model \n",
    "    linear_clf = PassiveAggressiveClassifier(random_state=666, max_iter=100, tol=1e-3,\n",
    "                                             early_stopping=True, validation_fraction=0.1)\n",
    "    \n",
    "    clf_cv_scores = cross_val_score(linear_clf,\n",
    "                                vectorize_train,\n",
    "                                y_train,\n",
    "                                cv = 5)\n",
    "    linear_clf.fit(vectorize_train, y_train)\n",
    "    pred = linear_clf.predict(vectorize_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    \n",
    "    #print(\"accuracy:   %0.3f\" % acc)\n",
    "    print(confusion_matrix(y_test, pred, labels=[0, 1]))\n",
    "    \n",
    "    return linear_clf, vectorizer, clf_cv_scores, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, use PAC on the text using the different vectorizers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Passive Aggresive Classifier with count vectorizer...\n",
      "[[346  59]\n",
      " [ 46 349]]\n",
      "Fitting Passive Aggresive Classifier with hash vectorizer...\n",
      "[[366  39]\n",
      " [ 34 361]]\n",
      "Fitting Passive Aggresive Classifier with tfidf vectorizer...\n",
      "[[378  27]\n",
      " [ 26 369]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Score avg</th>\n",
       "      <th>CV Score max</th>\n",
       "      <th>Holdout Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.877145</td>\n",
       "      <td>0.900156</td>\n",
       "      <td>0.89500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB count</td>\n",
       "      <td>0.883401</td>\n",
       "      <td>0.903276</td>\n",
       "      <td>0.89875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB tfidf</td>\n",
       "      <td>0.884020</td>\n",
       "      <td>0.915757</td>\n",
       "      <td>0.90625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF count</td>\n",
       "      <td>0.860425</td>\n",
       "      <td>0.866833</td>\n",
       "      <td>0.90125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF hash</td>\n",
       "      <td>0.828384</td>\n",
       "      <td>0.830259</td>\n",
       "      <td>0.86375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF tfidf</td>\n",
       "      <td>0.854720</td>\n",
       "      <td>0.856518</td>\n",
       "      <td>0.90125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PAC count</td>\n",
       "      <td>0.882466</td>\n",
       "      <td>0.892019</td>\n",
       "      <td>0.86875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PAC hash</td>\n",
       "      <td>0.915908</td>\n",
       "      <td>0.925117</td>\n",
       "      <td>0.90875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PAC tfidf</td>\n",
       "      <td>0.927783</td>\n",
       "      <td>0.948518</td>\n",
       "      <td>0.93375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model  CV Score avg  CV Score max  Holdout Score\n",
       "0   baseline      0.877145      0.900156        0.89500\n",
       "1   NB count      0.883401      0.903276        0.89875\n",
       "2   NB tfidf      0.884020      0.915757        0.90625\n",
       "3   RF count      0.860425      0.866833        0.90125\n",
       "4    RF hash      0.828384      0.830259        0.86375\n",
       "5   RF tfidf      0.854720      0.856518        0.90125\n",
       "6  PAC count      0.882466      0.892019        0.86875\n",
       "7   PAC hash      0.915908      0.925117        0.90875\n",
       "8  PAC tfidf      0.927783      0.948518        0.93375"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for vect in ['count', 'hash', 'tfidf']:\n",
    "    print(\"Fitting Passive Aggresive Classifier with \" + vect + \" vectorizer...\")\n",
    "    \n",
    "    model_temp, vect_temp, cv_scores_temp, test_score_temp = PAC(train_1, vect)\n",
    "    all_scores = hp.append_scores(all_scores, 'PAC ' + vect, cv_scores_temp, test_score_temp)\n",
    "    \n",
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only does the PAC run very quickly, the performance also is far higher then any others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model on Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the title contain relevant information to classify news?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the same but using the title only (and using tfidf only, since it worked significantly better):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[318  87]\n",
      " [ 84 311]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Score avg</th>\n",
       "      <th>CV Score max</th>\n",
       "      <th>Holdout Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.877145</td>\n",
       "      <td>0.900156</td>\n",
       "      <td>0.89500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB count</td>\n",
       "      <td>0.883401</td>\n",
       "      <td>0.903276</td>\n",
       "      <td>0.89875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB tfidf</td>\n",
       "      <td>0.884020</td>\n",
       "      <td>0.915757</td>\n",
       "      <td>0.90625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF count</td>\n",
       "      <td>0.860425</td>\n",
       "      <td>0.866833</td>\n",
       "      <td>0.90125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF hash</td>\n",
       "      <td>0.828384</td>\n",
       "      <td>0.830259</td>\n",
       "      <td>0.86375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF tfidf</td>\n",
       "      <td>0.854720</td>\n",
       "      <td>0.856518</td>\n",
       "      <td>0.90125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PAC count</td>\n",
       "      <td>0.882466</td>\n",
       "      <td>0.892019</td>\n",
       "      <td>0.86875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PAC hash</td>\n",
       "      <td>0.915908</td>\n",
       "      <td>0.925117</td>\n",
       "      <td>0.90875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PAC tfidf</td>\n",
       "      <td>0.927783</td>\n",
       "      <td>0.948518</td>\n",
       "      <td>0.93375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PAC on title tfidf</td>\n",
       "      <td>0.774299</td>\n",
       "      <td>0.784711</td>\n",
       "      <td>0.78625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  CV Score avg  CV Score max  Holdout Score\n",
       "0            baseline      0.877145      0.900156        0.89500\n",
       "1            NB count      0.883401      0.903276        0.89875\n",
       "2            NB tfidf      0.884020      0.915757        0.90625\n",
       "3            RF count      0.860425      0.866833        0.90125\n",
       "4             RF hash      0.828384      0.830259        0.86375\n",
       "5            RF tfidf      0.854720      0.856518        0.90125\n",
       "6           PAC count      0.882466      0.892019        0.86875\n",
       "7            PAC hash      0.915908      0.925117        0.90875\n",
       "8           PAC tfidf      0.927783      0.948518        0.93375\n",
       "9  PAC on title tfidf      0.774299      0.784711        0.78625"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_title, v_title, cv_pac_title, test_pac_title = PAC(train_1, 'tfidf', feature='title')\n",
    "\n",
    "all_scores = hp.append_scores(all_scores, 'PAC on title tfidf', cv_pac_title, test_pac_title)\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction is worse than the one on the text, but the classifier still classifies a considerable fraction of instances correctly.\n",
    "\n",
    "Since the title is often repeated at the beginning of the text, we will refrain from concatenating text and title. We tried it and it did not improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatize, Postag etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will explore how eliminating stopwords, lemmatizing and using a porter-stemmer affects model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eliminate stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[379  26]\n",
      " [ 28 367]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Score avg</th>\n",
       "      <th>CV Score max</th>\n",
       "      <th>Holdout Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.877145</td>\n",
       "      <td>0.900156</td>\n",
       "      <td>0.89500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB count</td>\n",
       "      <td>0.883401</td>\n",
       "      <td>0.903276</td>\n",
       "      <td>0.89875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB tfidf</td>\n",
       "      <td>0.884020</td>\n",
       "      <td>0.915757</td>\n",
       "      <td>0.90625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF count</td>\n",
       "      <td>0.860425</td>\n",
       "      <td>0.866833</td>\n",
       "      <td>0.90125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF hash</td>\n",
       "      <td>0.828384</td>\n",
       "      <td>0.830259</td>\n",
       "      <td>0.86375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF tfidf</td>\n",
       "      <td>0.854720</td>\n",
       "      <td>0.856518</td>\n",
       "      <td>0.90125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PAC count</td>\n",
       "      <td>0.882466</td>\n",
       "      <td>0.892019</td>\n",
       "      <td>0.86875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PAC hash</td>\n",
       "      <td>0.915908</td>\n",
       "      <td>0.925117</td>\n",
       "      <td>0.90875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PAC tfidf</td>\n",
       "      <td>0.927783</td>\n",
       "      <td>0.948518</td>\n",
       "      <td>0.93375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PAC on title tfidf</td>\n",
       "      <td>0.774299</td>\n",
       "      <td>0.784711</td>\n",
       "      <td>0.78625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PAC w/o stopwords</td>\n",
       "      <td>0.924970</td>\n",
       "      <td>0.942278</td>\n",
       "      <td>0.93250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  CV Score avg  CV Score max  Holdout Score\n",
       "0             baseline      0.877145      0.900156        0.89500\n",
       "1             NB count      0.883401      0.903276        0.89875\n",
       "2             NB tfidf      0.884020      0.915757        0.90625\n",
       "3             RF count      0.860425      0.866833        0.90125\n",
       "4              RF hash      0.828384      0.830259        0.86375\n",
       "5             RF tfidf      0.854720      0.856518        0.90125\n",
       "6            PAC count      0.882466      0.892019        0.86875\n",
       "7             PAC hash      0.915908      0.925117        0.90875\n",
       "8            PAC tfidf      0.927783      0.948518        0.93375\n",
       "9   PAC on title tfidf      0.774299      0.784711        0.78625\n",
       "10   PAC w/o stopwords      0.924970      0.942278        0.93250"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stopwords = hp.preprocess_data(train_1)\n",
    "m_stopwords, v_stopwords, cv_stopwords, test_stopwords = PAC(train_stopwords, 'tfidf', feature='text_stop')\n",
    "\n",
    "all_scores = hp.append_scores(all_scores, 'PAC w/o stopwords', cv_stopwords, test_stopwords)\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores are very similar to the previous PAC scores using tfidf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Porter Stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many words, there are several different conjugations and forms which however all share the same stem. For example, fish, fished, and fishing all refer to similar things. The porter stemmer will them all all of them down to fish, making them represent the same stem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[315  90]\n",
      " [ 93 302]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Score avg</th>\n",
       "      <th>CV Score max</th>\n",
       "      <th>Holdout Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.877145</td>\n",
       "      <td>0.900156</td>\n",
       "      <td>0.89500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB count</td>\n",
       "      <td>0.883401</td>\n",
       "      <td>0.903276</td>\n",
       "      <td>0.89875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB tfidf</td>\n",
       "      <td>0.884020</td>\n",
       "      <td>0.915757</td>\n",
       "      <td>0.90625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF count</td>\n",
       "      <td>0.860425</td>\n",
       "      <td>0.866833</td>\n",
       "      <td>0.90125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF hash</td>\n",
       "      <td>0.828384</td>\n",
       "      <td>0.830259</td>\n",
       "      <td>0.86375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF tfidf</td>\n",
       "      <td>0.854720</td>\n",
       "      <td>0.856518</td>\n",
       "      <td>0.90125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PAC count</td>\n",
       "      <td>0.882466</td>\n",
       "      <td>0.892019</td>\n",
       "      <td>0.86875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PAC hash</td>\n",
       "      <td>0.915908</td>\n",
       "      <td>0.925117</td>\n",
       "      <td>0.90875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PAC tfidf</td>\n",
       "      <td>0.927783</td>\n",
       "      <td>0.948518</td>\n",
       "      <td>0.93375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PAC on title tfidf</td>\n",
       "      <td>0.774299</td>\n",
       "      <td>0.784711</td>\n",
       "      <td>0.78625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PAC w/o stopwords</td>\n",
       "      <td>0.924970</td>\n",
       "      <td>0.942278</td>\n",
       "      <td>0.93250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PAC w/ porter stemmer</td>\n",
       "      <td>0.767726</td>\n",
       "      <td>0.795632</td>\n",
       "      <td>0.77125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  CV Score avg  CV Score max  Holdout Score\n",
       "0                baseline      0.877145      0.900156        0.89500\n",
       "1                NB count      0.883401      0.903276        0.89875\n",
       "2                NB tfidf      0.884020      0.915757        0.90625\n",
       "3                RF count      0.860425      0.866833        0.90125\n",
       "4                 RF hash      0.828384      0.830259        0.86375\n",
       "5                RF tfidf      0.854720      0.856518        0.90125\n",
       "6               PAC count      0.882466      0.892019        0.86875\n",
       "7                PAC hash      0.915908      0.925117        0.90875\n",
       "8               PAC tfidf      0.927783      0.948518        0.93375\n",
       "9      PAC on title tfidf      0.774299      0.784711        0.78625\n",
       "10      PAC w/o stopwords      0.924970      0.942278        0.93250\n",
       "11  PAC w/ porter stemmer      0.767726      0.795632        0.77125"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_porter = hp.preprocess_data(train_1, port = True)\n",
    "m_port, v_port, cv_port, test_port = PAC(train_porter, 'tfidf', feature='text_port')\n",
    "\n",
    "all_scores = hp.append_scores(all_scores, 'PAC w/ porter stemmer', cv_port, test_port)\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance is very bad. Indeed, stemming is not very sophisticated in the sense that it will also group together words which may have completely different meanings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatize words:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By performing lemmatizing, words belonging to the same family will be grouped to the same lemma. This is similar to stemming but more sophisticated. For example, good, better, best will all be turned into good. This reduces unwanted variation in wording of the same thing, but it could also mask crucial information for fake-news detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[374  31]\n",
      " [ 27 368]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Score avg</th>\n",
       "      <th>CV Score max</th>\n",
       "      <th>Holdout Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.877145</td>\n",
       "      <td>0.900156</td>\n",
       "      <td>0.89500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB count</td>\n",
       "      <td>0.883401</td>\n",
       "      <td>0.903276</td>\n",
       "      <td>0.89875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB tfidf</td>\n",
       "      <td>0.884020</td>\n",
       "      <td>0.915757</td>\n",
       "      <td>0.90625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF count</td>\n",
       "      <td>0.860425</td>\n",
       "      <td>0.866833</td>\n",
       "      <td>0.90125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF hash</td>\n",
       "      <td>0.828384</td>\n",
       "      <td>0.830259</td>\n",
       "      <td>0.86375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF tfidf</td>\n",
       "      <td>0.854720</td>\n",
       "      <td>0.856518</td>\n",
       "      <td>0.90125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PAC count</td>\n",
       "      <td>0.882466</td>\n",
       "      <td>0.892019</td>\n",
       "      <td>0.86875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PAC hash</td>\n",
       "      <td>0.915908</td>\n",
       "      <td>0.925117</td>\n",
       "      <td>0.90875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PAC tfidf</td>\n",
       "      <td>0.927783</td>\n",
       "      <td>0.948518</td>\n",
       "      <td>0.93375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PAC on title tfidf</td>\n",
       "      <td>0.774299</td>\n",
       "      <td>0.784711</td>\n",
       "      <td>0.78625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PAC w/o stopwords</td>\n",
       "      <td>0.924970</td>\n",
       "      <td>0.942278</td>\n",
       "      <td>0.93250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PAC w/ porter stemmer</td>\n",
       "      <td>0.767726</td>\n",
       "      <td>0.795632</td>\n",
       "      <td>0.77125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PAC w/ lemmatizer</td>\n",
       "      <td>0.916535</td>\n",
       "      <td>0.925117</td>\n",
       "      <td>0.92750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  CV Score avg  CV Score max  Holdout Score\n",
       "0                baseline      0.877145      0.900156        0.89500\n",
       "1                NB count      0.883401      0.903276        0.89875\n",
       "2                NB tfidf      0.884020      0.915757        0.90625\n",
       "3                RF count      0.860425      0.866833        0.90125\n",
       "4                 RF hash      0.828384      0.830259        0.86375\n",
       "5                RF tfidf      0.854720      0.856518        0.90125\n",
       "6               PAC count      0.882466      0.892019        0.86875\n",
       "7                PAC hash      0.915908      0.925117        0.90875\n",
       "8               PAC tfidf      0.927783      0.948518        0.93375\n",
       "9      PAC on title tfidf      0.774299      0.784711        0.78625\n",
       "10      PAC w/o stopwords      0.924970      0.942278        0.93250\n",
       "11  PAC w/ porter stemmer      0.767726      0.795632        0.77125\n",
       "12      PAC w/ lemmatizer      0.916535      0.925117        0.92750"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lemma = hp.preprocess_data(train_1, lemmatize = True)\n",
    "m_lemma, v_lemma, cv_lemma, test_lemma = PAC(train_lemma, 'tfidf', feature='text_lem')\n",
    "\n",
    "all_scores = hp.append_scores(all_scores, 'PAC w/ lemmatizer', cv_lemma, test_lemma)\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance is clearly reduced. The different forms of a lemma appear to contain information that helps classifying news. Perhaps, for example, superlatives are more widely used in fake news than in real ones.\n",
    "\n",
    "For this task, it seems to be better the less the data is processed, as little nuances in spelling and word choice contain valuable information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will approach the task in a different way and just try to create some features that could drive whether an article is fake news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe containing several other features and predict using that dataframe.\n",
    "\n",
    "The feature engineering creates the following features::\n",
    "- whether the word 'Trump' appears\n",
    "- length of text and title\n",
    "- counts of the various pos-tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2 = hp.create_features(train_1)\n",
    "train_3 = train_2[['label','trump_title', 'trump_text',\n",
    "                   'title_NN_count', 'title_VERB_count','title_ADJ_count', \n",
    "                   'text_NN_count', 'text_VERB_count','text_ADJ_count', \n",
    "                   'title_length', 'text_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>trump_title</th>\n",
       "      <th>trump_text</th>\n",
       "      <th>title_NN_count</th>\n",
       "      <th>title_VERB_count</th>\n",
       "      <th>title_ADJ_count</th>\n",
       "      <th>text_NN_count</th>\n",
       "      <th>text_VERB_count</th>\n",
       "      <th>text_ADJ_count</th>\n",
       "      <th>title_length</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2776</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  trump_title  trump_text  title_NN_count  title_VERB_count  \\\n",
       "0      0            0           1              10                 0   \n",
       "1      0            1           1              38                 0   \n",
       "2      1            0           0              21                 0   \n",
       "3      0            0           1              34                 0   \n",
       "4      1            0           1              19                 0   \n",
       "\n",
       "   title_ADJ_count  text_NN_count  text_VERB_count  text_ADJ_count  \\\n",
       "0                0           2776                0               0   \n",
       "1                0            988                0               0   \n",
       "2                0            960                0               0   \n",
       "3                0           1064                0               0   \n",
       "4                0            670                0               0   \n",
       "\n",
       "   title_length  text_length  \n",
       "0             7         1474  \n",
       "1            16          517  \n",
       "2             9          486  \n",
       "3            18          498  \n",
       "4            10          377  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now fit a normal model using these features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ti-idf vectorizer rf model\n",
    "def rf_model_standard(data,features):\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(data,feature=features)\n",
    "    \n",
    "    # pipeline\n",
    "    estimators = [('RF',RandomForestClassifier(random_state=666))]\n",
    "    pipe = Pipeline(estimators)\n",
    "    param_RF = {'RF__max_depth': [20,25],\n",
    "                'RF__n_estimators': [150,200]}\n",
    "    \n",
    "    # apply the estimators and parameters in pipeline\n",
    "    gridPipe = GridSearchCV(pipe, param_RF, cv=5, return_train_score=True)\n",
    "    model = gridPipe.fit(X_train, y_train)\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % acc)\n",
    "    print(confusion_matrix(y_test, pred, labels=[0, 1]))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.674\n",
      "[[259 146]\n",
      " [115 280]]\n"
     ]
    }
   ],
   "source": [
    "features = ['trump_title', 'trump_text',\n",
    "             'title_NN_count', 'title_VERB_count','title_ADJ_count', \n",
    "             'text_NN_count', 'text_VERB_count','text_ADJ_count', \n",
    "             'title_length', 'text_length'\n",
    "           ]\n",
    "m = rf_model_standard(train_3,features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model performance is very low. The standard NLP approach clearly works better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Less processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fake news, wrongs spellings and weird conjugations could give us a hint on whether an article is telling the truth. Thus, it is worth it to try fitting a model with the PAC where we do not turn everything to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload data\n",
    "train_0 = pd.read_csv('../data/fake_or_real_news_training.csv')\n",
    "# reprepare data\n",
    "train_4 = hp.prepare_data(train_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[383  22]\n",
      " [ 15 380]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Score avg</th>\n",
       "      <th>CV Score max</th>\n",
       "      <th>Holdout Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.877145</td>\n",
       "      <td>0.900156</td>\n",
       "      <td>0.89500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB count</td>\n",
       "      <td>0.883401</td>\n",
       "      <td>0.903276</td>\n",
       "      <td>0.89875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB tfidf</td>\n",
       "      <td>0.884020</td>\n",
       "      <td>0.915757</td>\n",
       "      <td>0.90625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF count</td>\n",
       "      <td>0.860425</td>\n",
       "      <td>0.866833</td>\n",
       "      <td>0.90125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF hash</td>\n",
       "      <td>0.828384</td>\n",
       "      <td>0.830259</td>\n",
       "      <td>0.86375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF tfidf</td>\n",
       "      <td>0.854720</td>\n",
       "      <td>0.856518</td>\n",
       "      <td>0.90125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PAC count</td>\n",
       "      <td>0.882466</td>\n",
       "      <td>0.892019</td>\n",
       "      <td>0.86875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PAC hash</td>\n",
       "      <td>0.915908</td>\n",
       "      <td>0.925117</td>\n",
       "      <td>0.90875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PAC tfidf</td>\n",
       "      <td>0.927783</td>\n",
       "      <td>0.948518</td>\n",
       "      <td>0.93375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PAC on title tfidf</td>\n",
       "      <td>0.774299</td>\n",
       "      <td>0.784711</td>\n",
       "      <td>0.78625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PAC w/o stopwords</td>\n",
       "      <td>0.924970</td>\n",
       "      <td>0.942278</td>\n",
       "      <td>0.93250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PAC w/ porter stemmer</td>\n",
       "      <td>0.767726</td>\n",
       "      <td>0.795632</td>\n",
       "      <td>0.77125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PAC w/ lemmatizer</td>\n",
       "      <td>0.916535</td>\n",
       "      <td>0.925117</td>\n",
       "      <td>0.92750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PAC not lowercase</td>\n",
       "      <td>0.941854</td>\n",
       "      <td>0.954758</td>\n",
       "      <td>0.95375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  CV Score avg  CV Score max  Holdout Score\n",
       "0                baseline      0.877145      0.900156        0.89500\n",
       "1                NB count      0.883401      0.903276        0.89875\n",
       "2                NB tfidf      0.884020      0.915757        0.90625\n",
       "3                RF count      0.860425      0.866833        0.90125\n",
       "4                 RF hash      0.828384      0.830259        0.86375\n",
       "5                RF tfidf      0.854720      0.856518        0.90125\n",
       "6               PAC count      0.882466      0.892019        0.86875\n",
       "7                PAC hash      0.915908      0.925117        0.90875\n",
       "8               PAC tfidf      0.927783      0.948518        0.93375\n",
       "9      PAC on title tfidf      0.774299      0.784711        0.78625\n",
       "10      PAC w/o stopwords      0.924970      0.942278        0.93250\n",
       "11  PAC w/ porter stemmer      0.767726      0.795632        0.77125\n",
       "12      PAC w/ lemmatizer      0.916535      0.925117        0.92750\n",
       "13      PAC not lowercase      0.941854      0.954758        0.95375"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_pac_lowercase, v_pac_not_lowercase, cv_pac_not_lowercase, test_pac_not_lowercase = PAC(train_4,feature='text', lowercase = False)\n",
    "\n",
    "all_scores = hp.append_scores(all_scores, 'PAC not lowercase', cv_pac_not_lowercase, test_pac_not_lowercase)\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, upper- and lower cases contain information valuable for classifying an article as fake or real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch\n",
    "\n",
    "Keeping this non-lowercase configuration, we run a gridsearch in order to find the best hyperparameters.\n",
    "\n",
    "We are tuning the following elements (all within the vectorizer):\n",
    "- max_df: ignore very frequent words, conceptually similar to eliminating stopwords (tune the max. frequency)\n",
    "- min_df: ignore very infrequent words (tune minimum number of occurences). Very infrequent words will tend to lead to overfitting, as they likely will not be found in most texts, reducing generalization power\n",
    "- ngram: group words together to n-grams (tuning n). In certain cases, a group of words if more informative than words by themselves. For example, \"fucking\" followed by \"awesome\" has a very different meaning from the two words by themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passive aggressive classifier with grid search cv\n",
    "def PAC_NGRAM(data, selection='tfidf', feature='text'):\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(data, feature=feature, random_state=666)\n",
    "    estimators = [   \n",
    "                    ('TF',TfidfVectorizer(stop_words='english', binary=True, lowercase=False,\n",
    "                                         norm='l2',sublinear_tf=False)\n",
    "                    ),\n",
    "                    ('PA',PassiveAggressiveClassifier(random_state=666, max_iter=1000, \n",
    "                                                      n_iter_no_change=10, tol=1e-3, \n",
    "                                                      early_stopping=True, loss='squared_hinge',\n",
    "                                                      fit_intercept= False,\n",
    "                                                      validation_fraction=0.1))\n",
    "                ]\n",
    "    pipe = Pipeline(estimators)\n",
    "    param_RF = {\n",
    "                'TF__max_df':[0.7, 0.8, 0.9],\n",
    "                'TF__min_df':[3,4,5,6],\n",
    "                'TF__ngram_range': [(1,1),(1,2),(1,3),(1,4),(3,4),(4,4)]\n",
    "                }\n",
    "    \n",
    "    # apply the estimators and parameters in pipeline\n",
    "    gridPipe = GridSearchCV(pipe, param_RF, cv=5, return_train_score=True)\n",
    "    model = gridPipe.fit(X_train, y_train)\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % acc)\n",
    "    print(confusion_matrix(y_test, pred, labels=[0, 1]))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.953\n",
      "[[379  20]\n",
      " [ 18 383]]\n"
     ]
    }
   ],
   "source": [
    "PAC_N = PAC_NGRAM(train_4,feature='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TF__max_df': 0.7, 'TF__min_df': 4, 'TF__ngram_range': (1, 4)}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAC_N.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PAC_tuned(data, feature='text'):\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(data, feature=feature)\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english',max_df=0.7, min_df = 4,\n",
    "                                 binary=True, lowercase=False, ngram_range = (1, 4),\n",
    "                                 norm='l2',sublinear_tf=False)\n",
    "    # transform data\n",
    "    vectorize_train = vectorizer.fit_transform(X_train)\n",
    "    vectorize_test = vectorizer.transform(X_test)\n",
    "    # model \n",
    "    linear_clf = PassiveAggressiveClassifier(random_state=666, max_iter=100, tol=1e-3,\n",
    "                                             early_stopping=True, validation_fraction=0.1)\n",
    "    \n",
    "    clf_cv_scores = cross_val_score(linear_clf,\n",
    "                                vectorize_train,\n",
    "                                y_train,\n",
    "                                cv = 5)\n",
    "    linear_clf.fit(vectorize_train, y_train)\n",
    "    pred = linear_clf.predict(vectorize_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    \n",
    "    #print(\"accuracy:   %0.3f\" % acc)\n",
    "    print(confusion_matrix(y_test, pred, labels=[0, 1]))\n",
    "    \n",
    "    return linear_clf, clf_cv_scores, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[386  19]\n",
      " [ 20 375]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Score avg</th>\n",
       "      <th>CV Score max</th>\n",
       "      <th>Holdout Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.877145</td>\n",
       "      <td>0.900156</td>\n",
       "      <td>0.89500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB count</td>\n",
       "      <td>0.883401</td>\n",
       "      <td>0.903276</td>\n",
       "      <td>0.89875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB tfidf</td>\n",
       "      <td>0.884020</td>\n",
       "      <td>0.915757</td>\n",
       "      <td>0.90625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF count</td>\n",
       "      <td>0.860425</td>\n",
       "      <td>0.866833</td>\n",
       "      <td>0.90125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF hash</td>\n",
       "      <td>0.828384</td>\n",
       "      <td>0.830259</td>\n",
       "      <td>0.86375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF tfidf</td>\n",
       "      <td>0.854720</td>\n",
       "      <td>0.856518</td>\n",
       "      <td>0.90125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PAC count</td>\n",
       "      <td>0.882466</td>\n",
       "      <td>0.892019</td>\n",
       "      <td>0.86875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PAC hash</td>\n",
       "      <td>0.915908</td>\n",
       "      <td>0.925117</td>\n",
       "      <td>0.90875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PAC tfidf</td>\n",
       "      <td>0.927783</td>\n",
       "      <td>0.948518</td>\n",
       "      <td>0.93375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PAC on title tfidf</td>\n",
       "      <td>0.774299</td>\n",
       "      <td>0.784711</td>\n",
       "      <td>0.78625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PAC w/o stopwords</td>\n",
       "      <td>0.924970</td>\n",
       "      <td>0.942278</td>\n",
       "      <td>0.93250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PAC w/ porter stemmer</td>\n",
       "      <td>0.767726</td>\n",
       "      <td>0.795632</td>\n",
       "      <td>0.77125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PAC w/ lemmatizer</td>\n",
       "      <td>0.916535</td>\n",
       "      <td>0.925117</td>\n",
       "      <td>0.92750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PAC not lowercase</td>\n",
       "      <td>0.941854</td>\n",
       "      <td>0.954758</td>\n",
       "      <td>0.95375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PAC Tuned</td>\n",
       "      <td>0.947481</td>\n",
       "      <td>0.957878</td>\n",
       "      <td>0.95125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  CV Score avg  CV Score max  Holdout Score\n",
       "0                baseline      0.877145      0.900156        0.89500\n",
       "1                NB count      0.883401      0.903276        0.89875\n",
       "2                NB tfidf      0.884020      0.915757        0.90625\n",
       "3                RF count      0.860425      0.866833        0.90125\n",
       "4                 RF hash      0.828384      0.830259        0.86375\n",
       "5                RF tfidf      0.854720      0.856518        0.90125\n",
       "6               PAC count      0.882466      0.892019        0.86875\n",
       "7                PAC hash      0.915908      0.925117        0.90875\n",
       "8               PAC tfidf      0.927783      0.948518        0.93375\n",
       "9      PAC on title tfidf      0.774299      0.784711        0.78625\n",
       "10      PAC w/o stopwords      0.924970      0.942278        0.93250\n",
       "11  PAC w/ porter stemmer      0.767726      0.795632        0.77125\n",
       "12      PAC w/ lemmatizer      0.916535      0.925117        0.92750\n",
       "13      PAC not lowercase      0.941854      0.954758        0.95375\n",
       "14              PAC Tuned      0.947481      0.957878        0.95125"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAC_N, cv_pact, test_pact = PAC_tuned(train_4,feature='text')\n",
    "\n",
    "all_scores = hp.append_scores(all_scores, 'PAC Tuned', cv_pact, test_pact)\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain the best model on the entire data and predict on the submission set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# passive aggressive classifier with grid search cv\n",
    "def PAC_FINAL(data, selection='tfidf', vectorize_max_df=0.7, vectorize_min_df=4, feature='text'):\n",
    "    # split data\n",
    "    X_train = data['text']\n",
    "    y_train = data['label']\n",
    "    estimators = [   \n",
    "                    ('TF',TfidfVectorizer(stop_words='english', binary=True, lowercase=False,\n",
    "                                          max_df=vectorize_max_df, min_df=vectorize_min_df,\n",
    "                                         norm='l2',sublinear_tf=False, ngram_range = (1, 4))\n",
    "                    ),\n",
    "                    ('PA',PassiveAggressiveClassifier(random_state=666, max_iter=1000, \n",
    "                                                      n_iter_no_change=10, tol=1e-3, \n",
    "                                                      early_stopping=True, loss='squared_hinge',\n",
    "                                                      fit_intercept= False,\n",
    "                                                      validation_fraction=0.1))\n",
    "                ]\n",
    "    pipe = Pipeline(estimators)\n",
    "    param_RF = {\n",
    "                'PA__C': [1]\n",
    "                }\n",
    "    \n",
    "    # apply the estimators and parameters in pipeline\n",
    "    gridPipe = GridSearchCV(pipe, param_RF, cv=5, return_train_score=True)\n",
    "    model = gridPipe.fit(X_train, y_train)\n",
    "\n",
    "#     pred = model.predict(X_test)\n",
    "#     acc = accuracy_score(y_test, pred)\n",
    "#     cv_results = gridPipe.cv_results_['mean_test_score']\n",
    "#     print(\"accuracy:   %0.3f\" % acc)\n",
    "#     print(confusion_matrix(y_test, pred, labels=[0, 1]))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = PAC_FINAL(train_4, feature='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission = pd.read_csv('../data/fake_or_real_news_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.956\n",
      "[[1099   65]\n",
      " [  37 1120]]\n"
     ]
    }
   ],
   "source": [
    "# Slight modifications to the preparation-function\n",
    "# because the submission data has a slightly different structure\n",
    "\n",
    "# m2 is the model from the PAC function\n",
    "# to apply the same process on submiss\n",
    "submission['prediction'] = m2.predict(submission['text'])\n",
    "submission.prediction[submission.prediction==0] = 'FAKE'\n",
    "submission.prediction[submission.prediction==1] = 'REAL'\n",
    "#submission = submission.set_index('ID')\n",
    "\n",
    "# answer is the dataset from kaggle\n",
    "# this is the dataset downloaded from kaggle so I didn't put it inside the repo\n",
    "answer = pd.read_csv('../../fake_or_real_news.csv')\n",
    "answer.rename(columns={'id':'ID'}, inplace=True)\n",
    "#answer = answer.set_index('ID')\n",
    "\n",
    "# left join on submission with prediction\n",
    "submission2 = submission.merge(answer[['ID','label']], how='left', on = \"ID\")\n",
    "\n",
    "# metrics\n",
    "acc = accuracy_score(submission2.label, submission2.prediction)\n",
    "print(\"accuracy:   %0.3f\" % acc)\n",
    "print(confusion_matrix(submission2.label, submission2.prediction, labels=['FAKE', 'REAL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
