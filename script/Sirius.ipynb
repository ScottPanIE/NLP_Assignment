{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize, WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.preprocessing import PolynomialFeatures,OneHotEncoder,LabelEncoder,StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/fake_or_real_news_training.csv')\n",
    "# the submission data has no label\n",
    "submission = pd.read_csv('../data/fake_or_real_news_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_en = stopwords.words('english')\n",
    "# define function to eliminate the stopwords\n",
    "def eliminate_stopwords(wordslist):\n",
    "    \"\"\"\n",
    "    stopwords_en is predefined outside of the function\n",
    "    \"\"\"\n",
    "    clean_list = [i for i in wordslist if i not in stopwords_en]\n",
    "    return clean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# postag\n",
    "def count_postags(words):\n",
    "    tagged_words = nltk.pos_tag(words)\n",
    "    num_noun = 0\n",
    "    num_verb = 0\n",
    "    num_adj = 0\n",
    "    for word in tagged_words:\n",
    "        if word[1] == 'NN':\n",
    "            num_noun += 1\n",
    "        elif word[1] == 'VERB':\n",
    "            num_verb += 1\n",
    "        elif word[1] == 'ADJ':\n",
    "            num_adj += 1\n",
    "    return num_noun, num_verb, num_adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the training set has 33 rows of data in the wrong format\n",
    "# we are going to simply remove the rows\n",
    "print(len(train.label.unique()))\n",
    "train = train[(train.label == 'REAL')|(train.label == 'FAKE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    \"\"\"\n",
    "    preprocessing + feature engineering\n",
    "    \"\"\"\n",
    "    # drop the redundent features -------- not yet\n",
    "    data = data.drop(['X1','X2'],axis=1)\n",
    "    # tokenize the title and text\n",
    "    data['title_token'] = data.title.apply(lambda x:word_tokenize(x))\n",
    "    data['text_token'] = data.text.apply(lambda x:word_tokenize(x))\n",
    "    # convert the target variable to 0 and 1\n",
    "    data.label = data.label.apply(lambda x:1 if x == 'REAL' else 0)\n",
    "\n",
    "    # eliminate the stopwords in title and text\n",
    "    data['titletoken_without_stopwords'] = data.title_token.apply(lambda x:eliminate_stopwords(x))\n",
    "    data['texttoken_without_stopwords'] = data.text_token.apply(lambda x:eliminate_stopwords(x))\n",
    "    # drop the redundent features\n",
    "    data = data.drop(['text','title'],axis=1)\n",
    "    # need to eliminate the punctuation as well? \n",
    "    # maybe do it with regex from the original title and text\n",
    "\n",
    "    ## feature engineering \n",
    "    \n",
    "    # count the postags\n",
    "    # title\n",
    "    data['title_postags'] = data.titletoken_without_stopwords.apply(lambda x:count_postags(x))\n",
    "    data['title_NN_count'] = data.title_postags.map(lambda x:x[0])\n",
    "    data['title_VERB_count'] = data.title_postags.map(lambda x:x[1])\n",
    "    data['title_ADJ_count'] = data.title_postags.map(lambda x:x[2])\n",
    "    # text\n",
    "    data['text_postags'] = data.texttoken_without_stopwords.apply(lambda x:count_postags(x))\n",
    "    data['text_NN_count'] = data.text_postags.map(lambda x:x[0])\n",
    "    data['text_VERB_count'] = data.text_postags.map(lambda x:x[1])\n",
    "    data['text_ADJ_count'] = data.text_postags.map(lambda x:x[2])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # create new features describe the length of the title and text, counting by words\n",
    "    # also maybe try with counting by letters\n",
    "    # and shall treat them as categorical variables group up with factor levels \n",
    "    data['title_length'] = data.title_token.apply(lambda x:len(x))\n",
    "    data['text_length'] = data.text_token.apply(lambda x:len(x))\n",
    "    # also highlight the keywords maybe?\n",
    "    \n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = prepare_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitdata(data, cols):\n",
    "    \"\"\"\n",
    "    cols: a list of columns names to use\n",
    "    \"\"\"\n",
    "    features = data[cols]\n",
    "    target = data.label\n",
    "    # first split into (train+test) and for holdout\n",
    "    TrainingSetX, X_holdout, TrainingSetY, y_holdout = train_test_split(features, target, \n",
    "                                                    test_size=0.10, stratify=target, \n",
    "                                                    random_state=666)\n",
    "    # split (train+test) into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(TrainingSetX, TrainingSetY, \n",
    "                                                test_size=0.20, stratify=TrainingSetY, \n",
    "                                                random_state=666)\n",
    "    # train and test use for modeling, holdout use for validating the model\n",
    "    print(\"spliting the data......\")\n",
    "    print(\"shape of train set: \", X_train.shape)\n",
    "    print(\"shape of test set: \", X_test.shape)\n",
    "    print(\"shape of holdout set: \", X_holdout.shape)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, X_holdout, y_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spliting the data......\n",
      "shape of train set:  (2879, 5)\n",
      "shape of test set:  (720, 5)\n",
      "shape of holdout set:  (400, 5)\n"
     ]
    }
   ],
   "source": [
    "cols2model = ['title_token', 'text_token', 'titletoken_without_stopwords', \n",
    "              'texttoken_without_stopwords', 'title_length']\n",
    "x1,y1,x2,y2,x3,y3 = splitdata(train_df, cols = cols2model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest classifier\n",
    "def model_rf(data,cols2model):\n",
    "    # split data\n",
    "    X_train, y_train, X_test, y_test, X_holdout, y_holdout = splitdata(train_df, cols = cols2model)\n",
    "    print('features for modeling :',X_train.columns.tolist())\n",
    "    # identify the categorical features and the numerical features\n",
    "    categorical_features = X_train.dtypes == 'category'\n",
    "    numerical_features = ~categorical_features\n",
    "    # pipeline\n",
    "    print('building up pipeline......')\n",
    "    estimators = [   \n",
    "                    ('ctf',ColumnTransformer([\n",
    "                                ('scale',StandardScaler(),\n",
    "                                         numerical_features),\n",
    "                                ('enc',OneHotEncoder(categories='auto',handle_unknown='ignore'),\n",
    "                                         categorical_features),\n",
    "                                            ])\n",
    "                    ),\n",
    "#                     ('poly', PolynomialFeatures(degree=1, include_bias=False, interaction_only=True)),\n",
    "                    ('RF',RandomForestClassifier(random_state=666,n_estimators=170,max_depth=22,n_jobs=-1))\n",
    "                ]\n",
    "    pipe = Pipeline(estimators)\n",
    "    \n",
    "    print('training the model......')\n",
    "    model = pipe.fit(X_train,y_train)\n",
    "    \n",
    "    print('training is done')\n",
    "    score_train = model.score(X_train,y_train) \n",
    "    score_test = model.score(X_test,y_test) \n",
    "    score_Holdout = model.score(X_holdout,y_holdout) \n",
    "    \n",
    "    print('training dataset mode1 is: %s'%(str(score_train1)))   \n",
    "    print('test dataset model is: %s'%(str(score_test1)))\n",
    "    print('Holdout dataset model1 is: %s'%(str(score_H1)))\n",
    "    \n",
    "    # in case needs to use the data to do some visualization or some other metrics\n",
    "    data_pack = (X_train, y_train, X_test, y_test, X_holdout, y_holdout)\n",
    "    return model, data_pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('this', 'DT'), ('an', 'DT'), ('cat', 'NN'), ('dog', 'NN')]\n",
      "Noun:  2\n",
      "Verb:  0\n",
      "Adj:  0\n"
     ]
    }
   ],
   "source": [
    "# postag\n",
    "def count_postags(words):\n",
    "    tagged_words = nltk.pos_tag(words)\n",
    "    num_noun = 0\n",
    "    num_verb = 0\n",
    "    num_adj = 0\n",
    "    for word in tagged_words:\n",
    "        if word[1] == 'NN':\n",
    "            num_noun += 1\n",
    "        elif word[1] == 'VERB':\n",
    "            num_verb += 1\n",
    "        elif word[1] == 'ADJ':\n",
    "            num_adj += 1\n",
    "    return num_noun, num_verb, num_adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>10194</td>\n",
       "      <td>Who rode it best? Jesse Jackson mounts up to f...</td>\n",
       "      <td>Leonardo DiCaprio to the rescue?</td>\n",
       "      <td>Who rode it best? Jesse Jackson mounts up to f...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>7375</td>\n",
       "      <td>Shallow 5.4 magnitude earthquake rattles centr...</td>\n",
       "      <td>shakes buildings in Rome</td>\n",
       "      <td>00 UTC © USGS Map of the earthquake's epicent...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>9097</td>\n",
       "      <td>ICE Agent Commits Suicide in NYC</td>\n",
       "      <td>Leaves Note Revealing Gov’t Plans to Round-up...</td>\n",
       "      <td>Email Print After writing a lengthy suicide no...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>9203</td>\n",
       "      <td>Political Correctness for Yuengling Brewery</td>\n",
       "      <td>What About Our Opioid Epidemic?</td>\n",
       "      <td>We Are Change \\n\\nIn today’s political climate...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>7559</td>\n",
       "      <td>STATE OF GEORGIA FIRES PASTOR BECAUSE OF HIS F...</td>\n",
       "      <td>GOVERNMENT DIDN’T “APPROVE” BIBLICAL SERMONS</td>\n",
       "      <td>Home › SOCIETY | US NEWS › STATE OF GEORGIA FI...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>8470</td>\n",
       "      <td>The Amish In America Commit Their Vote To Dona...</td>\n",
       "      <td>Mathematically Guaranteeing Him A Presidentia...</td>\n",
       "      <td>18 SHARE The Amish in America have committed t...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>6404</td>\n",
       "      <td>#BREAKING: SECOND Assassination Attempt On Tru...</td>\n",
       "      <td>Suspect Detained (LIVE BLOG)</td>\n",
       "      <td>We Are Change \\nDonald Trump on Saturday was q...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>10499</td>\n",
       "      <td>30th Infantry Division: “Work Horse of the Wes...</td>\n",
       "      <td>The Big Picture TV-211</td>\n",
       "      <td>Published on Oct 27, 2016 by Jeff Quitney The ...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>10492</td>\n",
       "      <td>TOP BRITISH GENERAL WARNS OF NUCLEAR WAR WITH ...</td>\n",
       "      <td>“THE END OF LIFE AS WE KNOW IT”</td>\n",
       "      <td>Paul Joseph Watson Senior British army officer...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>10138</td>\n",
       "      <td>Inside The Mind Of An FBI Informant</td>\n",
       "      <td>Terri Linnell Admits Role As Gov’t Snitch</td>\n",
       "      <td>Inside The Mind Of An FBI Informant; Terri Lin...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>5741</td>\n",
       "      <td>Why Trump Won</td>\n",
       "      <td>Why Clinton Lost</td>\n",
       "      <td>WashingtonsBlog \\nBy Robert Parry, the inves...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110</th>\n",
       "      <td>8748</td>\n",
       "      <td>WATCH: Mass Shooting Occurs During #TrumpRiot</td>\n",
       "      <td>Media Ignores (Video)</td>\n",
       "      <td>WATCH: Mass Shooting Occurs During #TrumpRio...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3130</th>\n",
       "      <td>6717</td>\n",
       "      <td>Jim Rogers: It’s Time To Prepare</td>\n",
       "      <td>Economic And Financial Collapse Imminent (VIDEO)</td>\n",
       "      <td>By: The Voice of Reason | Regardless of how mu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3706</th>\n",
       "      <td>9954</td>\n",
       "      <td>Incredible smoke haze seen outside NDTV office...</td>\n",
       "      <td>bursting of firecrackers suspected</td>\n",
       "      <td>Incredible smoke haze seen outside NDTV office...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                              title  \\\n",
       "308   10194  Who rode it best? Jesse Jackson mounts up to f...   \n",
       "911    7375  Shallow 5.4 magnitude earthquake rattles centr...   \n",
       "1010   9097                   ICE Agent Commits Suicide in NYC   \n",
       "1043   9203        Political Correctness for Yuengling Brewery   \n",
       "1630   7559  STATE OF GEORGIA FIRES PASTOR BECAUSE OF HIS F...   \n",
       "1900   8470  The Amish In America Commit Their Vote To Dona...   \n",
       "1968   6404  #BREAKING: SECOND Assassination Attempt On Tru...   \n",
       "2176  10499  30th Infantry Division: “Work Horse of the Wes...   \n",
       "2493  10492  TOP BRITISH GENERAL WARNS OF NUCLEAR WAR WITH ...   \n",
       "2549  10138                Inside The Mind Of An FBI Informant   \n",
       "3010   5741                                      Why Trump Won   \n",
       "3110   8748      WATCH: Mass Shooting Occurs During #TrumpRiot   \n",
       "3130   6717                   Jim Rogers: It’s Time To Prepare   \n",
       "3706   9954  Incredible smoke haze seen outside NDTV office...   \n",
       "\n",
       "                                                   text  \\\n",
       "308                    Leonardo DiCaprio to the rescue?   \n",
       "911                            shakes buildings in Rome   \n",
       "1010   Leaves Note Revealing Gov’t Plans to Round-up...   \n",
       "1043                    What About Our Opioid Epidemic?   \n",
       "1630       GOVERNMENT DIDN’T “APPROVE” BIBLICAL SERMONS   \n",
       "1900   Mathematically Guaranteeing Him A Presidentia...   \n",
       "1968                       Suspect Detained (LIVE BLOG)   \n",
       "2176                             The Big Picture TV-211   \n",
       "2493                    “THE END OF LIFE AS WE KNOW IT”   \n",
       "2549          Terri Linnell Admits Role As Gov’t Snitch   \n",
       "3010                                   Why Clinton Lost   \n",
       "3110                              Media Ignores (Video)   \n",
       "3130   Economic And Financial Collapse Imminent (VIDEO)   \n",
       "3706                 bursting of firecrackers suspected   \n",
       "\n",
       "                                                  label    X1   X2  \n",
       "308   Who rode it best? Jesse Jackson mounts up to f...  FAKE  NaN  \n",
       "911    00 UTC © USGS Map of the earthquake's epicent...  FAKE  NaN  \n",
       "1010  Email Print After writing a lengthy suicide no...  FAKE  NaN  \n",
       "1043  We Are Change \\n\\nIn today’s political climate...  FAKE  NaN  \n",
       "1630  Home › SOCIETY | US NEWS › STATE OF GEORGIA FI...  FAKE  NaN  \n",
       "1900  18 SHARE The Amish in America have committed t...  FAKE  NaN  \n",
       "1968  We Are Change \\nDonald Trump on Saturday was q...  FAKE  NaN  \n",
       "2176  Published on Oct 27, 2016 by Jeff Quitney The ...  FAKE  NaN  \n",
       "2493  Paul Joseph Watson Senior British army officer...  FAKE  NaN  \n",
       "2549  Inside The Mind Of An FBI Informant; Terri Lin...  FAKE  NaN  \n",
       "3010    WashingtonsBlog \\nBy Robert Parry, the inves...  FAKE  NaN  \n",
       "3110    WATCH: Mass Shooting Occurs During #TrumpRio...  FAKE  NaN  \n",
       "3130  By: The Voice of Reason | Regardless of how mu...  FAKE  NaN  \n",
       "3706  Incredible smoke haze seen outside NDTV office...  FAKE  NaN  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maybe we can try the neural network?\n",
    "train[train.X1 == 'FAKE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'REAL', 'FAKE'], dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train[train.X2 != np.nan]\n",
    "# if train.X2 == FAKE or REAL, then X1 is text\n",
    "train.X2.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>9</td>\n",
       "      <td>Planned Parenthood’s lobbying effort</td>\n",
       "      <td>pay raises for federal workers</td>\n",
       "      <td>and the future Fed rates</td>\n",
       "      <td>PLANNED PARENTHOOD’S LOBBYING GETS AGGRESSIVE....</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>6268</td>\n",
       "      <td>Chart Of The Day: Since 2009—–Recovery For The 5%</td>\n",
       "      <td>Stagnation for the 95%</td>\n",
       "      <td>Chart Of The Day: Since 2009 Recovery For The 5%</td>\n",
       "      <td>Stagnation for the 95%</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID                                              title  \\\n",
       "2184     9               Planned Parenthood’s lobbying effort   \n",
       "3537  6268  Chart Of The Day: Since 2009—–Recovery For The 5%   \n",
       "\n",
       "                                 text  \\\n",
       "2184   pay raises for federal workers   \n",
       "3537           Stagnation for the 95%   \n",
       "\n",
       "                                                 label  \\\n",
       "2184                          and the future Fed rates   \n",
       "3537  Chart Of The Day: Since 2009 Recovery For The 5%   \n",
       "\n",
       "                                                     X1    X2  \n",
       "2184  PLANNED PARENTHOOD’S LOBBYING GETS AGGRESSIVE....  REAL  \n",
       "3537                           Stagnation for the 95%    FAKE  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train.X2 == 'REAL')|(train.X2 == 'FAKE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.labe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-baa4778bcc07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/intro_python/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'label'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
